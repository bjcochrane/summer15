---
title: <center>Oâ€™Meara Workshop</center>
author: <center>Bruce Cochrane</center>
date: <center>`r format(Sys.Date(),format="%%B %%d %%Y")`</center>
output: 
    html_document:
       css: Chapter.css
       toc: yes
       toc_depth: 5
---
### Pre-planning

We'll have the Geospiza data loaded:

```{r}
geotree <- read.nexus("http://www.r-phylo.org/mediawiki/images/0/02/Geospiza.nex")
geodata <-read.table("http://www.r-phylo.org/mediawiki/images/5/5c/Geospiza.txt")
```

And a little cleanup:

```{r}
geotree <- drop.tip(geotree, "olivacea")
plot(geotree)
nodelabels()
```
Pull our and name the peak data:

```{r}
bkd <-geodata$beakD
names(bkd) <-row.names(geodata)
bkd
```
```{r}
library()
```
Copied from O'Meara
```{r}
library('ape')
library('phytools')
library('TreeSim')
library('geiger')
library('OUwie')
library('treebase')
library('taxize')
library('RColorBrewer')
install.packages('rfishbase') #b/c this isn't in the task view
library('rfishbase')

```
Some more:

```{r}
#first, let's simulate a tree
#because TreeSim returns a list of trees, even with just one tree simulated, take first element in list.
phy <- sim.bd.taxa(n=20,numbsim=1,lambda=1,mu=0.9,complete=FALSE)[[1]] 

#let's look at this:
plot(phy)
```
Create correlated traces

```{r}
vcv.data <- matrix(data=c(.5,0.3, 0.3, 0.45), nrow=2, ncol=2, byrow=TRUE)
print(vcv.data)
data <- sim.corrs(phy, vcv.data, anc=c(17,3))

```
```{r}
plot(data[,1],data[,2],pch=16,bty="n")
```

Put on tree
```{r}
par(mfrow=c(1,2))
```
And plot on trees
```{r}
contMap(phy, data[,1])
contMap(phy, data[,2], direction="leftwards")
```
Look at it in phylospace
```{r}
par(mfcol=c(1,1))
phylomorphospace(phy, data)
```

Independent contrasts - 
```{r}
pic.X <- pic(data[,1], phy)
pic.Y <- pic(data[,2], phy)

par(mfcol=c(1,2))
plot(data[,1], data[,2], pch=16, bty="n", col="gray")
plot(pic.X, pic.Y, pch=16, bty="n", col="gray")

```
Need to positivize the contrasts:
```{r}
PositivizeContrasts <- function(x, y) {
  x.positivized <- x * sign(x)
	y.positivized <- y * sign(x)
	
	return(cbind(x.positivized, y.positivized))
}

```

And plot
```{r}
positivized.results <- PositivizeContrasts(pic.X, pic.Y)
points(positivized.results[,1], positivized.results[,2], pch="x", col="red")
```
Correlation test
```{r}
print(cor.test(positivized.results[,1], positivized.results[,2]))
```
```{r}
help(package="geiger")
```
It has a good set of internal data sets to explore
```{r}
data.x <- data[,1]
geiger.brownian <-  fitContinuous(phy, data.x, SE=NA, ncores=1,niter=1000)
print(geiger.brownian)
```
```{r}
str(geiger.brownian)
```

```{r}
print(paste("true rate was", vcv.data[1,1], "; estimated rate was", geiger.brownian$opt$sigsq))
```
Do a replication
```{r}
num.reps <- 25
optimal.sigsq.vector <- rep(NA, num.reps)
```
```{r}
for (rep.index in sequence(num.reps)) {
  optimal.sigsq.vector[rep.index] <- fitContinuous(phy, data.x, SE=NA, ncores=1, control=list(niter=2))$opt$sigsq
}
par(mfrow=c(1,1))
plot(optimal.sigsq.vector, log="y", xlab="replicate", ylab="sigma squared", pch=16, bty="n")
abline(h=vcv.data[1,1], col="red")
```
### Reading Treebase

So the following does an rOpenSci search for the trees
```{r}
fish.trees <- search_treebase("menadoensis", by="taxon", branch_lengths=TRUE, max_trees=30)
```
```{r}
fish.phy <-fish.trees[[1]]
plot(fish.phy,show.tip.label=FALSE)
```
Not proportional to time; ape functions not real worthwhile but use it.
```{r}
fish.chronogram <- chronos(fish.phy)
class(fish.chronogram) <-"phylo"
```
```{r}
plot(fish.chronogram,show.tip.label=FALSE)
```

Now get data on sizes
```{r}
fish.sizes <-getSize(value="length")
```
Hmmm.  might want to take this a bit further
```{r}
fish.quant <-getQuantTraits()
```


Making names consistent:
```{r}
fish.chronogram.name.resolve <- gnr_resolve(names = gsub("_", " ",fish.chronogram$tip.label), best_match_only=TRUE)


print(fish.chronogram.name.resolve)
```
Get the names in order
```{r}
fish.chronogram.name.resolve.ordered <- fish.chronogram.name.resolve$results[order(as.numeric(row.names(fish.chronogram.name.resolve$results))),] #puts it back in input order

fish.chronogram.renamed <- fish.chronogram
fish.chronogram.renamed$tip.label <- fish.chronogram.name.resolve.ordered$matched_name
```
Check to see
```{r}
print(cbind(fish.chronogram$tip.label, fish.chronogram.renamed$tip.label))
```
Size names cleanup - just remove dashes to save time
```{r}
fish.sizes.renamed <- fish.sizes
names(fish.sizes.renamed) <- gsub("_", " ", names(fish.sizes))

#and check!
print(cbind(names(fish.sizes.renamed), names(fish.sizes)))
```
```{r}
fish.sizes.renamed <- fish.sizes.renamed[!is.na(fish.sizes.renamed)] #get rid of NAs
```
Now combine tree with size
```{r}
fish.resolved.all <- treedata(fish.chronogram.renamed, fish.sizes.renamed, sort=TRUE)
fish.phy.final <- fish.resolved.all$phy
fish.data.final <- fish.resolved.all$data

```
### Model comparison

UE - brownian motion attached to a rubber band.
```{r}
library("OUwie")
```
Under development - needs check to see if data are sufficient to estimate parameters.  Simulated from OUwie
```{r}
data(tworegime)
tree
```
Plot tree with node labels
```{r}
select.reg<-character(length(tree$node.label)) 
select.reg[tree$node.label == 1] <- "black"
select.reg[tree$node.label == 2] <- "red"
plot(tree) 
nodelabels(pch=21, bg=select.reg)
```
```{r}
#Now to run it!
#This takes longer than you may be used to. 
#We're a bit obsessive about doing multiple starts and in general
#performing a thorough numerical search. It took you 3+ years
#to get the data, may as well take an extra five minutes to 
#get an accurate answer
nodeBased.OUMV <- OUwie(tree,trait,model="OUMV", simmap.tree=FALSE, diagn=FALSE)
print(nodeBased.OUMV)
#What do the numbers mean?
```
So what we are doing is looking for rates that differ in two regions.  Now to apply to a few models:

mods <-c()
```{r}
mods <-c("BM1","BMS","OU1","OUM","OUMV","OUMA","OUMVA")
mod.test <-lapply(mods, function(x) OUwie(tree,trait,model=x,simmap.tree=FALSE, diagn=FALSE))
```
So that should have given us a list of three.  Let's check
```{r}
mod.test[[3]]
```
Going to extract AICC values
```{r}
AICc.values<-sapply(mod.test, "[[", "AICc")
names(AICc.values)<-mods
AICc.values<-AICc.values-min(AICc.values)
AICc.values
```

Extract the best (which is OUMV)
```{r}
best<-mod.test[[which.min(AICc.values)]] #store for later

print(best) #prints info on best model

```
```{r}
#Get the AIC values, put in a vector
AIC.values<-sapply(mod.test, "[[", "AIC")
names(AIC.values)<-mods

#Get the loglik values, put in a vector
loglik.values<-sapply(mod.test, "[[", "loglik")
names(loglik.values)<-mods

#AIC = -2lnL + 2K
#AIC + 2 lnL = 2K
#K = (AIC + 2 lnl)/2

K.values = (AIC.values + 2 * loglik.values)/2

#Check
print(K.values)
```
Now do some plotting:

```{r}
my.palette<-brewer.pal(length(K.values),"Dark2")

multiplier.range <- seq(from=0, to=10, by=1)

plot(x=c(-0.5+min(multiplier.range), 1.05*max(multiplier.range)), y=range(-2*max(loglik.values), -2*min(loglik.values)+max(multiplier.range)*max(K.values)), xlab="Multiplier", ylab="*IC", bty="n", type="n")

for (model.index in sequence(length(K.values))) {
  lines(x=multiplier.range, y=-2*loglik.values[model.index]+multiplier.range * K.values[model.index], col=my.palette[model.index])	
	text(max(multiplier.range), y=-2*loglik.values[model.index]+max(multiplier.range) * K.values[model.index], names(K.values[model.index]), col=my.palette[model.index], pos=4, cex=0.5)
	text(min(multiplier.range), y=-2*loglik.values[model.index]+min(multiplier.range) * K.values[model.index], names(K.values[model.index]), col=my.palette[model.index], pos=2, cex=0.5)
}

abline(v=2, lty="dotted") #line for regular AIC
```

So this shows that the debate over weighting the number of parameters matters.

Now set a bunch of alpha values and calculate likelihood for each
```{r}
alpha.values<-seq(0.00001, to=2 , length.out=50)
```
```{r}
likelihood.values <- rep(NA, length(alpha.values))
for (iteration in sequence(length(alpha.values))) {
  likelihood.values[iteration] <- OUwie.fixed(tree, trait, model="OUMV", alpha=rep(alpha.values[iteration],2), sigma.sq=best$solution[2,], theta=best$theta[,1])$loglik
}
```

And we need to plot
```{r}
plot(x=alpha.values, y=likelihood.values, xlab="Alpha", ylab="Neg lnL", type="l", bty="n")

points(x=best$solution[1,1], y=best$loglik, pch=16, col="red")
text(x=best$solution[1,1], y=best$loglik, "unconstrained best", pos=4, col="red")

abline(h=best$loglik-2, lty="dotted") #Two log-likelihood 
```

```{r}
library (akima)
```
```{r}
nreps<-400
theta1.points<-c(best$theta[1,1], rnorm(nreps-1, best$theta[1,1], 5*best$theta[1,2])) #center on optimal value, have extra variance
theta2.points<-c(best$theta[2,1], rnorm(nreps-1, best$theta[2,1], 5*best$theta[2,2])) #center on optimal value, have extra variance
likelihood.values<-rep(NA,nreps)

for (iteration in sequence(nreps)) {
  likelihood.values[iteration] <- OUwie.fixed(tree, trait, model="OUMV", alpha=best$solution[1,], sigma.sq=best$solution[2,], theta=c(theta1.points[iteration], theta2.points[iteration]))$loglik
}
```
```{r}
likelihood.differences<-(-(likelihood.values-max(likelihood.values)))
```
Make contour map
```{r}
interpolated.points<-interp(x=theta1.points, y=theta2.points, z= likelihood.differences, linear=FALSE, extrap=TRUE, xo=seq(min(theta1.points), max(theta1.points), length = 400), yo=seq(min(theta2.points), max(theta2.points), length = 400))
  
contour(interpolated.points, xlim=range(c(theta1.points, theta2.points)),ylim=range(c(theta1.points, theta2.points)), xlab="Theta 1", ylab="Theta 2", levels=c(2,5,10),add=FALSE,lwd=1, bty="n", asp=1)

points(x=best$theta[1,1], y=best$theta[2,1], col="red", pch=16)

points(x=trait$X[which(trait$Reg==1)],y=rep(min(c(theta1.points, theta2.points)), length(which(trait$Reg==1))), pch=18, col=rgb(0,0,0,.3)) #the tip values in regime 1, plotted along x axis
points(y=trait$X[which(trait$Reg==2)],x=rep(min(c(theta1.points, theta2.points)), length(which(trait$Reg==2))), pch=18, col=rgb(0,0,0,.3)) #the tip values in regime 2, plotted along y axis

```
So what this shows is the optimum value for the two estimated parameters (akin to alphas in the OU model)
